---
title: 吴恩达的机器学习-睡前英语听力小助手
date: 2021-05-23 21:03:24
tags: 机器学习
categories: 机器学习
cover: https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210721212215.png
---



# AWSL，吴恩达的声音太性感了。以后听着机器学习睡觉我觉得是一种该死的享受嗷！！！

<!--more-->

- I try to write down my understanding and feelings in this course all in English to exercise my English and strengthen my understanding of deep learning.





## Some Resources

[PPT of this course](https://gitee.com/Mei_HW/deeplearning.ai-andrew-ng)





# Week One



## Supervised Learning

- You have to provide the x and y data to train the model , and use the model to predict the result. This is the reason why we call it supervised learning.
- The picture of the performance together with the the size of the neural network and the amount of data！

![image-20210524193421511](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/20210524193421.png)

- three factors:
  - Data
  - Computation
  - Algorithms



# Week Two

## Logistic Regression

- Binary Classification is the using environment of logistic regression
- Taking the picture input as an example , if you use a picture of (n*m)pixels , the input x will be 3\*m\*n. Because in the computer , the picture is stored in three matrix which represents the red , green and blue. So if you enter a picture , in fact you enter 3\*m\*n data to the model. And the result of this model is y whose scope is only 0 and 1 because it's a binary classification problem.
- So the way that you get the training matrix is :

![image-20210524200806515](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/20210524200806.png)

- At above picture , a line is actually a input of a picture , which is what i mention above 3\*m\*n. 
- The shape is also a function in python:

![image-20210524201048716](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/20210524201048.png)

- To train the logistic function , you need a cost function

### Loss Funtion and cost function:

- measure how well our algorithm is running
- Gradient ascend may not find a good result
- Usually used function：

![image-20210706095944605](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210706095951.png)

- It will be viewed as：

![image-20210706100130948](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210706100131.png)

- Cost funtion：
  - Meaure how well you're doing on a single training example.
- The different usages of the function：
  - Loss function -> single training example
  - Cost function -> cost of your parameters(the whole project)



### Gradient Descent：

- Gradient Descent is to made to get the minimum of the cost funciton:

![image-20210706160544579](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210706160544.png)

- How to update w and b：

![image-20210706160848200](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210706160848.png)

Actually because the character of the cost function. There is a "minimum" of the function's picture. So what you need to do is to find a way to update the value of w(or b) to get closer to the best point.





#### Learning rate：

- The rate of updating the $\omega$ at the picture above.($\alpha$)
- $\omega = \omega - \alpha \cdot \frac{dJ(\omega)}{d\omega}$





## Forward and backword

- **Chain Rule** is very important in computing derivatives
- backword calculation：
  - Final output may is more important
  - So you can present every the derivatives by using $\frac{dFindOutputVar}{dVar}$
- **Backword propogation is to use chain rules to calculate derivatives.**
- **Forward propogation is to use chain rules to calculate cost function.**



### Used in Logistic:

- ![image-20210707152536190](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210707152536.png)

- ![image-20210707152334478](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210707152341.png)
-  calculate the answer of derivatives:

![image-20210707152839609](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210707152839.png)

- Last step: Using the derivatives to update the value of $\omega$ and $\beta$
  - Updating step is to use the skill mentioned above to get close to the low lost point！！！



## Using m examples to train Logistic Model：

- Vertorization is a technology to help you get rid of the "for" loop
- For is less efficient because you have to use for to two parts: the first part is to get each sample , the second part is to get each character , so actually this will make your code less efficient.



### Vertorization:

- This is the meaning of numpy which is used in machine learning !!!
- numpy's built-in function is important
- coding skills
  1. ![image-20210708092659628](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708092659.png)





- Used in forward propogation:

![image-20210708194610771](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708194611.png)

- Used in backword propogation:

![image-20210708195844432](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708195844.png)



### Broadcasting:

- 计算一列的和：`Matrix.sum(axis=0)`
- **reshape** is to make sure the right of your matrix
- What python do in calculating matrixes？Examples:
  - ![image-20210708200532962](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708200533.png)
  - ![image-20210708200619491](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708200619.png)
  - ![image-20210708200651257](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708200651.png)



#### Solve bugs:

- `a = np.random.randn(5)` not recommend , strongly recommend that you use `a = np.random.randn(5,1)`
- a = np.random.randn(5): Create a rank 1 array ==Don't use this！！！==
- a = np.random.randn(5,1)
- To make sure the shape: `assert(a.shape == (5,1))`
- Use reshape `a = a.reshape(5,1)` to solve this problem too!!! Don't be shy to use reshape function!!!



### How to get Logistic?

![image-20210708213350670](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708213350.png)

- Cost function:
  - maximum likelihood estimation
  - ![image-20210708213801645](https://cdn.jsdelivr.net/gh/alexanderliu-creator/cloudimg/img/20210708213801.png)

